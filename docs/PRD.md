# PostgreSQL Narrow-to-Wide Table Migration Project PRD

## 1. 프로젝트 개요

### 1.1 목적
PostgreSQL의 대용량 narrow type 테이블(`tenant.tbl_data_timeseries`)을 wide type 테이블로 마이그레이션하여 데이터 접근성과 성능을 향상시킨다.

### 1.2 배경
- 현재 narrow type 테이블에서 데이터 조회 시 복잡한 WHERE 조건과 JOIN이 필요
- ship_id별로 분리된 wide type 테이블로 변환하여 쿼리 성능 개선
- 실시간 데이터 처리(1분 간격, 15초 데이터 수집)와 기존 데이터 마이그레이션을 동시에 수행
- 대용량 데이터 처리 시 발생할 수 있는 트러블슈팅을 사전에 고려하여 안정적인 마이그레이션 구현

## 2. 기술적 요구사항

### 2.1 소스 테이블 스키마
```sql
CREATE TABLE tenant.tbl_data_timeseries (
    id bigserial NOT NULL,
    ship_id text NOT NULL,
    data_channel_id text NOT NULL,
    created_time timestamp NOT NULL,
    server_created_time timestamp NULL,
    bool_v bool NULL,
    str_v text NULL,
    long_v int8 NULL,
    double_v float8 NULL,
    value_format varchar(50) NULL,
    CONSTRAINT data_timeseries_pk PRIMARY KEY (ship_id, data_channel_id, created_time)
);
```

### 2.2 타겟 테이블 구조
- **테이블 명 규칙**: `tbl_data_timeseries_{ship_id}`
- **예시**: `tbl_data_timeseries_IMO9976903`, `tbl_data_timeseries_IMO9976915`
- **컬럼 구조**:
  - `created_time` (timestamp, PRIMARY KEY)
  - `data_channel_id` 값들이 컬럼으로 변환
  - `value_format`에 따른 데이터 타입 매핑

### 2.3 데이터 타입 매핑 규칙
- **Decimal** → `double_v` 컬럼의 값 사용
- **Integer** → `long_v` 컬럼의 값 사용  
- **String** → `str_v` 컬럼의 값 사용
- **Boolean** → `bool_v` 컬럼의 값 사용

### 2.4 컬럼 타입 규칙
- `created_time`: timestamp (PRIMARY KEY)
- `data_channel_id` 값들로 생성되는 컬럼들: **text type**
- 인덱스: `created_time` 기준으로 생성

## 3. 기능 요구사항

### 3.1 테이블 스키마 생성
- **입력**: 60분간의 샘플 데이터 (더 정확한 스키마 분석을 위해)
- **출력**: 각 ship_id별 wide type 테이블 스키마
- **기능**: 
  - 고유한 data_channel_id 값들을 text 타입 컬럼으로 변환
  - value_format에 따른 적절한 데이터 타입 매핑 규칙 적용
  - 인덱스 생성 (`created_time` 기준)

### 3.2 기존 데이터 마이그레이션
- **대상**: 특정 시점 이전의 모든 데이터
- **방식**: 청크 기반 배치 처리 (24시간 단위)
- **고려사항**: 
  - 대용량 데이터 처리 최적화 (청크 기반)
  - 진행상황 모니터링 (청크별 진행률)
  - 오류 처리 및 재시도 로직 (청크 단위)
  - 메모리 효율성 (50,000 레코드 배치 처리)

### 3.3 실시간 데이터 처리
- **주기**: 1분 간격 (15초 데이터 수집)
- **기능**:
  - 새로운 데이터를 해당 ship_id 테이블에 삽입
  - 새로운 data_channel_id 발견 시 테이블 스키마 동적 업데이트 (ALTER TABLE)
  - value_format에 따른 올바른 컬럼에 데이터 삽입
### 3.4 동시 처리 전략 (Concurrent Strategy)
- **실시간 처리**: 새로운 데이터를 즉시 처리
- **백그라운드 백필**: 기존 데이터를 백그라운드에서 청크 단위로 처리
- **멀티스레딩**: 실시간과 백필을 동시에 실행
- **Zero Downtime**: 실시간 데이터 수집 중단 없이 마이그레이션

### 3.5 cutoff_time 관리
- **영구 저장**: 마이그레이션 완료 시점을 파일에 저장
- **자동 복구**: 프로세스 재시작 시 자동으로 cutoff_time 로드
- **데이터 중복 방지**: cutoff_time 이후 데이터만 실시간 처리
- **일관성 보장**: 마이그레이션과 실시간 처리 간 데이터 중복 방지

## 4. 비기능 요구사항

### 4.1 성능
- 대용량 데이터 처리 시 메모리 효율성 (청크 기반 처리)
- 배치 처리 시 데이터베이스 부하 최소화 (50,000 레코드 배치)
- 실시간 처리 지연시간 최소화 (1초 이내)
- 동시 처리 시 리소스 최적화 (멀티스레딩)
- 청크 기반 처리로 메모리 사용량 최적화

### 4.2 안정성
- 데이터 손실 방지
- 트랜잭션 롤백 지원
- 오류 발생 시 복구 메커니즘

### 4.3 확장성
- 새로운 ship_id 자동 감지 및 처리
- 새로운 data_channel_id 동적 컬럼 추가

## 5. 데이터베이스 연결 정보

### 5.1 연결 정보
- **호스트**: 222.99.122.73:25432
- **데이터베이스**: tenant_builder
- **사용자**: tapp
- **비밀번호**: tapp.123

### 5.2 접근 권한 요구사항
- 테이블 생성 권한
- 데이터 읽기/쓰기 권한
- 스키마 변경 권한

## 6. 구현 계획

### 6.1 Phase 1: 스키마 분석 및 생성
1. 샘플 데이터 수집 (10분간)
2. 고유한 data_channel_id 추출
3. 각 ship_id별 테이블 스키마 생성
4. 테이블 생성 스크립트 생성

### 6.2 Phase 2: 기존 데이터 마이그레이션
1. 배치 마이그레이션 스크립트 개발
2. 진행상황 모니터링 기능 구현
3. 오류 처리 및 재시도 로직 구현
4. 마이그레이션 실행

### 6.3 Phase 3: 실시간 데이터 처리
1. 실시간 데이터 수집 모듈 개발
2. 동적 스키마 업데이트 기능 구현
3. 데이터 일관성 검증 로직 구현
4. 모니터링 및 알림 시스템 구현

## 7. 대용량 PostgreSQL 마이그레이션 트러블슈팅

### 7.1 성능 관련 이슈

#### 7.1.1 메모리 부족 문제
- **증상**: 대용량 데이터 처리 시 OOM(Out of Memory) 발생
- **원인**: 전체 데이터를 메모리에 로드하려는 시도
- **해결방안**:
  - 청크 단위 배치 처리 (예: 10,000건씩)
  - 커서 기반 스트리밍 처리
  - PostgreSQL 설정 최적화 (`work_mem`, `shared_buffers` 조정)

#### 7.1.2 인덱스 성능 저하
- **증상**: 데이터 삽입 시 인덱스 업데이트로 인한 성능 저하
- **원인**: 실시간 인덱스 업데이트 부하
- **해결방안**:
  - 마이그레이션 중 인덱스 일시 비활성화
  - 배치 삽입 후 인덱스 재생성
  - 부분 인덱스 활용 고려

#### 7.1.3 락 경합 문제
- **증상**: 테이블 락으로 인한 다른 작업 블로킹
- **원인**: 대용량 DDL/DML 작업 시 락 경합
- **해결방안**:
  - 작업 시간대 조정 (업무 시간 외)
  - 온라인 스키마 변경 도구 활용
  - 작은 단위로 나누어 처리

### 7.2 데이터 일관성 이슈

#### 7.2.1 트랜잭션 타임아웃
- **증상**: 긴 트랜잭션으로 인한 타임아웃 발생
- **원인**: 대용량 데이터 처리 시 트랜잭션 지속 시간 초과
- **해결방안**:
  - 작은 단위 트랜잭션으로 분할
  - 자동 커밋 모드 활용
  - 체크포인트 기반 처리

#### 7.2.2 데이터 타입 변환 오류
- **증상**: value_format과 실제 데이터 타입 불일치
- **원인**: 데이터 품질 문제 또는 스키마 변경 이력
- **해결방안**:
  - 데이터 검증 로직 구현
  - 예외 데이터 별도 처리
  - 변환 전 데이터 품질 검사

### 7.3 운영 환경 이슈

#### 7.3.1 디스크 공간 부족
- **증상**: 마이그레이션 중 디스크 공간 부족
- **원인**: 원본 + 타겟 테이블 동시 존재
- **해결방안**:
  - 디스크 공간 모니터링
  - 단계별 마이그레이션 (테이블별)
  - 임시 파일 정리 자동화

#### 7.3.2 네트워크 연결 불안정
- **증상**: 장시간 작업 중 연결 끊김
- **원인**: 네트워크 타임아웃 또는 불안정한 연결
- **해결방안**:
  - 연결 풀링 및 재연결 로직
  - 작업 상태 저장 및 재시작 기능
  - 네트워크 모니터링

### 7.4 실시간 처리 이슈

#### 7.4.1 동적 스키마 변경 충돌
- **증상**: 실시간 처리 중 스키마 변경으로 인한 충돌
- **원인**: 동시에 여러 data_channel_id 추가 요청
- **해결방안**:
  - 스키마 변경 락 메커니즘
  - 큐 기반 순차 처리
  - 스키마 버전 관리

#### 7.4.2 데이터 중복 처리
- **증상**: 동일한 데이터의 중복 삽입
- **원인**: 실시간 처리와 배치 처리 간 중복
- **해결방안**:
  - UPSERT 로직 구현
  - 타임스탬프 기반 중복 체크
  - 처리 상태 추적

## 8. 위험 요소 및 대응 방안

### 8.1 기술적 위험
- **위험**: 대용량 데이터 처리 시 메모리 부족
- **대응**: 청크 단위 처리 및 스트리밍 방식 적용

### 8.2 운영 위험
- **위험**: 실시간 데이터 처리 중 오류 발생
- **대응**: 자동 재시도 및 알림 시스템 구현

### 8.3 데이터 위험
- **위험**: 마이그레이션 중 데이터 손실
- **대응**: 백업 생성 및 트랜잭션 기반 처리

## 9. 성공 지표

### 9.1 기능적 지표
- 모든 기존 데이터의 성공적인 마이그레이션
- 실시간 데이터 처리 정확도 99.9% 이상
- 새로운 ship_id/data_channel_id 자동 감지 및 처리
- value_format별 데이터 타입 매핑 정확도 100%

### 9.2 성능 지표
- 쿼리 성능 향상 (기존 대비 50% 이상)
- 실시간 데이터 처리 지연시간 1초 이내
- 시스템 리소스 사용률 최적화
- 마이그레이션 처리 속도 (시간당 처리 건수)

### 9.3 안정성 지표
- 트러블슈팅 발생률 최소화
- 데이터 손실률 0%
- 시스템 가용성 99.9% 이상

## 10. 향후 확장 계획

### 10.1 단기 계획
- 마이그레이션 도구의 웹 인터페이스 개발
- 실시간 모니터링 대시보드 구축
- 트러블슈팅 자동화 도구 개발

### 10.2 장기 계획
- 다른 narrow type 테이블에 대한 마이그레이션 지원
- 클라우드 환경으로의 확장
- 자동화된 스키마 최적화 기능
- 머신러닝 기반 성능 최적화

---

**문서 버전**: 1.0.0  
**작성일**: 2024년  
**작성자**: 개발팀  
**승인자**: 프로젝트 매니저
